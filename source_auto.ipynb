{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    '셀트리온':'00413046',\n",
    "    '에이치엘비':'00199252'\n",
    "}\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def dart(f):\n",
    "    for key in dict:\n",
    "\n",
    "        url = 'http://dart.fss.or.kr/api/companyRSS.xml?crpCd='+dict[key]\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "        items = soup.find_all(\"item\")\n",
    "        f.write(\"DART\")\n",
    "        f.write(\"\\n\")\n",
    "        for item in items:\n",
    "            f.write(item.title.text)\n",
    "            f.write(\"\\n\")\n",
    "            f.write(item.guid.text)\n",
    "            f.write(\"\\n\")\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaverNews\n",
    "- url에서 \"&sort=date\"이므로 최신순 정렬이다.\n",
    "- url에서 news를 blog로 수정하면 blog 자료가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = <클라이언트 아이디>\n",
    "CLIENT_SECRET = <클라이언트 시크릿>\n",
    "SEARCH_WORD = \"에이치엘비\"\n",
    "\n",
    "def naver_news(f):\n",
    "    import os\n",
    "    import sys\n",
    "    import json\n",
    "    import urllib.request\n",
    "\n",
    "    client_id = CLIENT_ID\n",
    "    client_secret = CLIENT_SECRET\n",
    "    encText = urllib.parse.quote(SEARCH_WORD)\n",
    "    url = \"https://openapi.naver.com/v1/search/news?query=\" + encText + \"&sort=date\"\n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        res = response_body.decode('utf-8')\n",
    "        json_res = json.loads(res)\n",
    "        f.write(\"Naver News\")\n",
    "        f.write(\"\\n\")\n",
    "        for item in json_res[\"items\"]:\n",
    "            f.write(item[\"title\"])\n",
    "            f.write(\"\\n\")\n",
    "            f.write(item[\"link\"])\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        f.write(\"Error Code:\" + rescode)\n",
    "        f.write(\"\\n\")\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = {\n",
    "    \"메디파나\" : \"http://www.medipana.com/news/news_list_new.asp?Page=1&sWord=&sDate=&MainKind=C&NewsKind=67&vCount=20&vKind=1\",\n",
    "    \"약업닷컴\" : \"https://www.yakup.com/news/index.html?cat=12\",\n",
    "    \"바이오스펙테이터\" : \"http://www.biospectator.com/section/section_list.php?MID=11100\"\n",
    "}\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def bio_news(f):\n",
    "    for key in url.keys():\n",
    "        res = requests.get(url[key])\n",
    "        soup = BeautifulSoup(res.content, \"lxml\")\n",
    "\n",
    "        if key == \"메디파나\":\n",
    "            titles = soup.find_all(\"span\", class_=[\"tit\", \"infor\"]) #다중 클래스 선택\n",
    "            i = 0\n",
    "            f.write(\"메디파나\")\n",
    "            f.write(\"\\n\")\n",
    "            for title in titles:\n",
    "                f.write(title.text)\n",
    "                f.write(\"\\n\")\n",
    "                if i % 2 == 1:\n",
    "                    f.write(\"http://www.medipana.com\"+title.parent[\"href\"][2:])\n",
    "                    f.write(\"\\n\")\n",
    "                i += 1\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        elif key == \"약업닷컴\":\n",
    "            titles = soup.find_all(\"h6\")\n",
    "            f.write(\"약업닷컴\")\n",
    "            f.write(\"\\n\")\n",
    "            for title in titles:\n",
    "                f.write(title.text)\n",
    "                f.write(\"\")\n",
    "                f.write(title.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.text)\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"https://www.yakup.com/\"+title.a[\"href\"])\n",
    "                f.write(\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        elif key == \"바이오스펙테이터\":\n",
    "            titles = soup.find_all(\"strong\", class_=\"article_tit\")\n",
    "            f.write(\"바이오스펙테이터\")\n",
    "            f.write(\"\\n\")\n",
    "            for title in titles:\n",
    "                f.write(title.text.strip())\n",
    "                f.write(\"\")\n",
    "                f.write(title.next_sibling.next_sibling.next_sibling.next_sibling.find(\"span\", class_=\"date\").text)\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"http://www.biospectator.com/\"+title.a[\"href\"])\n",
    "                f.write(\"\\n\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution(writing notepad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"C:\\\\Users\\\\user\\\\Desktop\\\\source.txt\", \"a\", encoding=\"UTF8\")\n",
    "dart(f)\n",
    "naver_news(f)\n",
    "bio_news(f)\n",
    "f.close()\n",
    "\n",
    "import os\n",
    "os.system(\"C:\\\\Users\\\\user\\\\Desktop\\\\source.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
